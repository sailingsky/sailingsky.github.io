[{"content":"ThreadPoolExecutor这个应该很多人都用过，主要用来多线程任务并行执行。当然如果用不好，也会有很多意想不到的坑，比如常见的队列用错导致堆溢出。今天说的不是这个问题，这是之前线上遇到的问题。\n代码 线程业务任务：\n1 2 3 4 5 6 7 8 9 10 11 12 public class ThreadTask implements Runnable{ @Override public void run() { try { //模拟业务代码执行时间1s Thread.sleep(1000); logger.info(Thread.currentThread().getName()+\u0026#34; \u0026#34;+System.currentTimeMillis()); } catch (InterruptedException e) { throw new RuntimeException(e); } } } 业务代码中使用ThreadPoolExecutor线程池：\n1 2 3 4 5 6 7 8 9 ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(5,10,3L, TimeUnit.SECONDS,new ArrayBlockingQueue\u0026lt;\u0026gt;(10)); for (int i = 0; i \u0026lt; 30; i++) { ThreadTask threadTask = new ThreadTask(); threadPoolExecutor.submit(threadTask); } threadPoolExecutor.shutdown(); 这个代码咋看起来，也没有什么问题吧。线程池大小，阻塞队列也用的有界队列，线程池最后也进行了关闭处理。然而，实际情况却是线程池不会关闭，因为代码根本不会执行到关闭那行。这样当代码不断执行，创建的线程池越来越多，线程池却没被关闭，最终拖垮系统。\n原因 我们一步步来梳理下：\n来了30个线程任务，扔到了线程池里 核心线程数5，那么先创建5个线程执行任务，还剩25个任务 接着扔10个任务到阻塞队列中，还剩15个任务 发现还是不够，最大线程数还没超过10，那行，再创建5个线程跑任务，还剩10个任务 那这剩下的10个任务就根据拒绝策略处理了。 submit 提交任务后，会调用 execute方法，当发现无法再添加worker执行任务时，就会调用拒绝策略的reject方法：\n问题呢，就出在最后一步的拒绝策略，因为源代码中线程池初始化时，并没有指定具体的拒绝策略，就会采用默认的defaultHandler.defaultHandler是AbortPolicy.\n看下AbortPolicy 里面处理拒绝逻辑是，抛出了个RejectExecutionException.\n很明显，抛出异常后，后面的代码执行就被中断了，threadPoolExecutor.shutdown() 这个也就不会被执行了。\n优化 将代码用try-catch包起来，像这样：\n1 2 3 4 5 6 7 8 9 10 try { for (int i = 0; i \u0026lt; 30; i++) { ThreadTask threadTask = new ThreadTask(); threadPoolExecutor.submit(threadTask); } }catch (Exception ex){ log.error(ex.getMessage()); }finally{ threadPoolExecutor.shutdown(); } 初始化线程池时，指定其他的拒绝策略\n1 2 ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(5,10,3L, TimeUnit.SECONDS,new ArrayBlockingQueue\u0026lt;\u0026gt;(10), new ThreadPoolExecutor.DiscardPolicy()); 或者自定义拒绝策略\n1 2 3 4 5 6 public class TaskRejectHandler implements RejectedExecutionHandler { @Override public void rejectedExecution(Runnable r, ThreadPoolExecutor executor) { logger.error(\u0026#34;{} had been reject \u0026#34;,r.toString()); } } 4.加大队列长度，核心线程数大小和最大线程数大小。\n","date":"2024-03-27T11:26:32+08:00","image":"https://sailingsky.github.io/p/threadpoolexecutor%E4%BD%BF%E7%94%A8%E4%B8%8D%E5%BD%93%E7%9A%84bug/neom-LAj90eAXOZA-unsplash_hu5459c0360c2b0cb7a147d2df0eb350ca_4721418_120x120_fill_q75_box_smart1.jpg","permalink":"https://sailingsky.github.io/p/threadpoolexecutor%E4%BD%BF%E7%94%A8%E4%B8%8D%E5%BD%93%E7%9A%84bug/","title":"Threadpoolexecutor使用不当的bug"},{"content":"之前的sharding-jdbc文章里读写分离水平分片采用了取余的方式，即按照当前实例数简单粗暴区域分片。而取余来说简单易懂，带来的问题也是显而易见的，就是在进行扩容的时候，会导致很多数据的迁移和查询失效。 一致性哈希算法能够避免以上的问题，其扩容也只会影响一小部分数据，具体的一致性哈希可参考网上很多的博客，这里不再赘述。\n一致性哈希算法定义 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 package com.example.shardingjdbcdemo.sharding; import lombok.extern.slf4j.Slf4j; import org.apache.shardingsphere.sharding.api.sharding.standard.PreciseShardingValue; import org.apache.shardingsphere.sharding.api.sharding.standard.RangeShardingValue; import org.apache.shardingsphere.sharding.api.sharding.standard.StandardShardingAlgorithm; import java.util.Collection; import java.util.SortedMap; import java.util.TreeMap; /** * @Author: zhangsj * @Date: 2024-03-23 20:00 */ @Slf4j public class ConsistencyShardingAlgorithm implements StandardShardingAlgorithm\u0026lt;Long\u0026gt; { SortedMap\u0026lt;Integer,String\u0026gt; consistentMap = new TreeMap\u0026lt;\u0026gt;(); @Override public String doSharding(Collection\u0026lt;String\u0026gt; availableTargetNames, PreciseShardingValue\u0026lt;Long\u0026gt; shardingValue) { if(consistentMap.isEmpty()){ //根据实际节点，创建出对应256个虚拟节点 for(String targetName: availableTargetNames){ for(int j=0;j\u0026lt;256;j++){ String key = targetName+\u0026#34;-\u0026#34;+j; consistentMap.put(getHash(key),targetName); } } } int shardingHash = getHash(shardingValue.getValue()+\u0026#34;\u0026#34;); //得到大于该分片hash值的所有map SortedMap\u0026lt;Integer,String\u0026gt; subMap = consistentMap.tailMap(shardingHash); if(subMap.isEmpty()){ Integer firstKey = consistentMap.firstKey(); return consistentMap.get(firstKey); }else{ return subMap.get(subMap.firstKey()); } } @Override public Collection\u0026lt;String\u0026gt; doSharding(Collection\u0026lt;String\u0026gt; availableTargetNames, RangeShardingValue\u0026lt;Long\u0026gt; shardingValue) { return availableTargetNames; } @Override public void init() { } @Override public String getType() { return \u0026#34;Consistency\u0026#34;; } //使用FNV1_32_HASH算法计算服务器的Hash值 private static int getHash(String str) { final int p = 16777619; int hash = (int) 2166136261L; for (int i = 0; i \u0026lt; str.length(); i++) { hash = (hash ^ str.charAt(i)) * p; } hash += hash \u0026lt;\u0026lt; 13; hash ^= hash \u0026gt;\u0026gt; 7; hash += hash \u0026lt;\u0026lt; 3; hash ^= hash \u0026gt;\u0026gt; 17; hash += hash \u0026lt;\u0026lt; 5; // 如果算出来的值为负数则取其绝对值 if (hash \u0026lt; 0) { hash = Math.abs(hash); } log.info(\u0026#34;key:{},hash:{}\u0026#34;,str,hash); return hash; } } 配置中设置 由于一致性哈希一般针对数据库来设置，所以一致性哈希分片配置只放在数据库上。关键词consistency\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 server: port: 8080 spring: shardingsphere: # 内存模式 mode: type: Memory datasource: names: master0,master1,slave0,slave1 master0: type: com.zaxxer.hikari.HikariDataSource driver-class-name: com.mysql.jdbc.Driver jdbc-url: jdbc:mysql://192.168.65.131:3306/db_order username: root password: root master1: type: com.zaxxer.hikari.HikariDataSource driver-class-name: com.mysql.jdbc.Driver jdbc-url: jdbc:mysql://192.168.65.131:3308/db_order username: root password: root slave0: type: com.zaxxer.hikari.HikariDataSource driver-class-name: com.mysql.jdbc.Driver jdbc-url: jdbc:mysql://192.168.65.131:3307/db_order username: root password: root slave1: type: com.zaxxer.hikari.HikariDataSource driver-class-name: com.mysql.jdbc.Driver jdbc-url: jdbc:mysql://192.168.65.131:3309/db_order username: root password: root #sql日志输出 props: sql-show: true rules: # 读写分离配置 readwrite-splitting: data-sources: rwds0: type: Static props: #写数据源名称 write-data-source-name: master0 #读数据源名称 read-data-source-names: slave0 # 负载均衡算法名称 load-balancer-name: alg_round rwds1: type: Static props: #写数据源名称 write-data-source-name: master1 #读数据源名称 read-data-source-names: slave1 # 负载均衡算法名称 load-balancer-name: alg_round # 负载均衡算法类型 load-balancers: alg_round: type: RANDOM # 分片配置 sharding: tables: t_order: actual-data-nodes: rwds$-\u0026gt;{0..1}.t_order$-\u0026gt;{0..1} # 分库策略 database-strategy: standard: # 分片列名称 sharding-column: user_id #分片算法名称 sharding-algorithm-name: consistency # 分表策略 table-strategy: standard: sharding-column: id sharding-algorithm-name: alg_mod #分布式序列策略配置 key-generate-strategy: column: id key-generator-name: alg_snowflake sharding-algorithms: #一致性哈希 consistency: type: CLASS_BASED props: strategy: standard algorithmClassName: com.example.shardingjdbcdemo.sharding.ConsistencyShardingAlgorithm # 分片算法取余，按分片数2取余 alg_mod: type: mod props: sharding-count: 2 #主键生成策略 key-generators: alg_snowflake: type: SNOWFLAKE 当然，分片算法不止可以用标准算法，也可采用其他的分片算法，具体可参照官方文档 分片 和 分片算法\n","date":"2024-03-23T21:48:33+08:00","image":"https://sailingsky.github.io/post/java/sharding-jdbc/pexels-google-deepmind-17483874.jpg","permalink":"https://sailingsky.github.io/p/sharding-jdbc%E5%AE%9E%E7%8E%B0%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C%E5%88%86%E7%89%87/","title":"sharding-jdbc实现一致性哈希分片"},{"content":"题目描述 给你一个整数数组 cost ，其中 cost[i] 是从楼梯第 i 个台阶向上爬需要支付的费用。一旦你支付此费用，即可选择向上爬一个或者两个台阶。\n你可以选择从下标为 0 或下标为 1 的台阶开始爬楼梯。\n请你计算并返回达到楼梯顶部的最低花费。\n示例 1：\n1 2 3 4 5 输入：cost = [10,15,20] 输出：15 解释：你将从下标为 1 的台阶开始。 - 支付 15 ，向上爬两个台阶，到达楼梯顶部。 总花费为 15 。 解题思路 和之前leetcode-70 爬楼梯类似，第i个阶梯的最小代价公式为:d(i)=min(d(i-1),d(i-2))+c(i)\n代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 public int minCostClimbingStairs(int[] cost) { if(cost==null||cost.length==0) return 0; if(cost.length==1) return cost[0]; //前一，二个阶梯的代价 int first =cost[0],second=cost[1]; for(int i=2;i\u0026lt;cost.length;i++){ //当前楼梯的最小代价 int cur = Math.min(first,second)+cost[i]; first=second; second=cur; } return Math.min(first,second); } 效果 ","date":"2024-03-11T21:56:55+08:00","image":"https://sailingsky.github.io/post/algorithm/pexels-google-deepmind-18069816.jpg","permalink":"https://sailingsky.github.io/p/leetcode-746-%E6%9C%80%E5%B0%8F%E4%BB%A3%E4%BB%B7%E7%88%AC%E6%A5%BC%E6%A2%AF/","title":"Leetcode-746 最小代价爬楼梯"},{"content":"题目描述 假设你正在爬楼梯。需要 n 阶你才能到达楼顶。\n每次你可以爬 1 或 2 个台阶。你有多少种不同的方法可以爬到楼顶呢？\n示例 1：\n1 2 3 4 5 输入：n = 2 输出：2 解释：有两种方法可以爬到楼顶。 1. 1 阶 + 1 阶 2. 2 阶 解题思路 当n=1, 有1种（1阶）方法，即f(1)=1;\n当n=2, 有2种（1 阶 + 1 阶;2阶）方法，即f(2)=2;\n当n=3, 有3种(1 阶 + 1 阶+1阶;2阶+1阶；1阶+2阶)方法，即f(3)=3=f(2)+f(1);\n利用数学归纳法，可得f(n)=f(n-1)+f(n-2),典型的斐波那契数列;\n代码 1 2 3 4 5 6 7 8 9 10 public int climbStairs(int n) { int first= 1,second=1; for(int i =1 ;i\u0026lt;n;i++){ int third = first+second; first=second; second=third; } return second; } 效果 ","date":"2024-03-11T21:39:57+08:00","image":"https://sailingsky.github.io/post/algorithm/pexels-google-deepmind-18069816.jpg","permalink":"https://sailingsky.github.io/p/leetcode-70-%E7%88%AC%E6%A5%BC%E6%A2%AF/","title":"Leetcode-70 爬楼梯"},{"content":"题目描述 给定两个整数数组 preorder 和 inorder ，其中 preorder 是二叉树的先序遍历， inorder 是同一棵树的中序遍历，请构造二叉树并返回其根节点。\n示例 1:\n1 2 输入: preorder = [3,9,20,15,7], inorder = [9,3,15,20,7] 输出: [3,9,20,null,null,15,7] 解题思路 利用规则，前序数组规则是：根-左-右 ，中序数组规则是：左-根-右 以前序数组为主，确定好左子树的长度（而左子树的长度，可以从中序数组中根左边数字长度获得），接着就能分别对左右子树进行递归构造。 代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 /** * * @param preorder 前序数组 * @param preStart 前序数组开始坐标 * @param preEnd 前序数组结束坐标 * @param inStart 中序数组开始坐标 * @param inMap * @return */ private TreeNode buildTree(int[] preorder,int preStart,int preEnd,int inStart,Map\u0026lt;Integer,Integer\u0026gt; inMap){ if(preStart\u0026gt;preEnd) return null; TreeNode root = new TreeNode(preorder[preStart]); //根节点在中序数组中的位置(根据中序规则，根节点左边的都为左子树) int rootIdx = inMap.get(preorder[preStart]); //中序数组中左子树长度 int leftLen = rootIdx-inStart; //构建左子树 root.left = buildTree(preorder,preStart+1,preStart+leftLen,inStart,inMap); //右子树 root.right = buildTree(preorder,preStart+leftLen+1,preEnd,rootIdx+1,inMap); return root; } //前序数组规则：根-左-右；中序数组规则：左-根-右 public TreeNode buildTree(int[] preorder, int[] inorder) { //中序数组辅助map，存放数组元素和其对应的位置 Map\u0026lt;Integer,Integer\u0026gt; inMap = new HashMap\u0026lt;\u0026gt;(); for (int i=0;i\u0026lt;inorder.length;i++) inMap.put(inorder[i], i); return buildTree(preorder,0, preorder.length, 0,inMap); } 效果： ","date":"2024-03-11T21:25:08+08:00","image":"https://sailingsky.github.io/post/algorithm/pexels-google-deepmind-18069816.jpg","permalink":"https://sailingsky.github.io/p/leetcode-105-%E4%BB%8E%E5%89%8D%E5%BA%8F%E4%B8%8E%E4%B8%AD%E5%BA%8F%E9%81%8D%E5%8E%86%E5%BA%8F%E5%88%97%E6%9E%84%E9%80%A0%E4%BA%8C%E5%8F%89%E6%A0%91/","title":"Leetcode-105 从前序与中序遍历序列构造二叉树"},{"content":"最近有个需求，想把语音转成文字，网上搜了搜，能用的免费的没多少，某飞的居然要收88大洋，太贵了，买不起根本买不起。后面寻着了个免费的方法，采用whisper进行语音文字转换。\n薅个云主机 进入google云盘(https://drive.google.com/drive/home),新建-更多-Google Colaboratory.\n接着修改代码运行时类型，更改相应配置：\n这里选择的运行时：Python3 ,硬件加速器 T4 GPU\n然后保存之，右上角连接到对应的主机。\n安装whisper及配套组件 在代码栏中输入以下内容，并运行\n1 2 !pip install git+https://github.com/openai/whisper.git !sudo apt update \u0026amp;\u0026amp; sudo apt install ffmpeg 上传要转文字的音频或视频文件：\n接着执行转换命令：\n1 !whisper \u0026#34;meeting_01.mp4\u0026#34; --model large-v3 根据文件大小，会等待一段时间。最终成功后会在文件夹下生成转换出来的 srt文件，txt文件，json文件等，识别率也还不错。\n","date":"2024-02-22T15:44:27+08:00","image":"https://sailingsky.github.io/post/ai/igor-omilaev-eGGFZ5X2LnA-unsplash.jpg","permalink":"https://sailingsky.github.io/p/whisper%E8%AF%AD%E9%9F%B3%E8%BD%AC%E6%96%87%E5%AD%97/","title":"Whisper语音转文字"},{"content":"前提装好mysql服务，还有配套的prometheus以及grafana服务。\n下载mysqld_exporter 官方下载地址：https://github.com/prometheus/mysqld_exporter/releases/download/v0.15.1/mysqld_exporter-0.15.1.windows-amd64.zip\n在mysql中添加mysqld_exporter的账号\n1 2 3 4 5 6 7 CREATE USER \u0026#39;exporter\u0026#39;@\u0026#39;localhost\u0026#39; IDENTIFIED BY \u0026#39;exporter\u0026#39;; GRANT PROCESS, REPLICATION CLIENT, SELECT ON *.* TO \u0026#39;exporter\u0026#39;@\u0026#39;localhost\u0026#39;; ALTER USER exporter@localhost IDENTIFIED WITH mysql_native_password BY \u0026#39;exporter\u0026#39;; flush privileges; 在mysqld-exporter目录下新建my.cnf,加入配置\n1 2 3 [client] user=exporter password=exporter 启动mysqld_exporter:\n1 mysqld_exporter.exe --config.my-cnf=my.cnf 如图：\nprometheus中的prometheus.yml增加配置：\n1 2 3 4 5 6 7 8 # The job name is added as a label `job=\u0026lt;job_name\u0026gt;` to any timeseries scraped from this config. - job_name: \u0026#34;mysql\u0026#34; # metrics_path defaults to \u0026#39;/metrics\u0026#39; # scheme defaults to \u0026#39;http\u0026#39;. static_configs: - targets: [\u0026#34;localhost:9104\u0026#34;] 启动prometheus，在页面上可看到新加的mysql grafana配置好prometheus数据源，导入dashboard,我这用的这个dashboard. https://grafana.com/grafana/dashboards/17320-1-mysqld-exporter-dashboard/ 最终效果. ","date":"2024-01-15T18:46:18+08:00","image":"https://sailingsky.github.io/p/prometheues%E7%9B%91%E6%8E%A7mysql/Grafana-0_hu9300c52758da7e33076209d5894eb9b9_53190_120x120_fill_box_smart1_3.png","permalink":"https://sailingsky.github.io/p/prometheues%E7%9B%91%E6%8E%A7mysql/","title":"prometheues监控mysql"},{"content":"安装 下载源码包\u0026amp;编译 1 2 3 4 wget https://download.redis.io/redis-7.2.3.tar.gz tar -zxf redis-7.2.3.tar.gz cd redis-7.2.3 make 修改配置redis.conf 1 2 #禁用保护模式，生产勿用！ protected-mode no 主从模式 主节点： 1 ./src/redis-server /data/redis-master1/redis.conf 从节点： 修改redis.conf中端口相关及主从复制主节点配置 1 2 3 port 6380 # replicaof 主节点IP 主节点端口 replicaof 127.0.0.1 6379 replicaof 127.0.0.1 6379 也可以直接在从节点客户端执行命令： 1 redis\u0026gt; replicaof 127.0.0.1 6379 启动从节点后，可在日志输出中看到主从同步成功。 验证 主节点：\n1 set test this is a key 从节点：\n1 2 3 ./src/redis-cli -p 6380 127.0.0.1:6380\u0026gt; get test 哨兵模式 配置哨兵节点 配置sentinel.conf文件,其他哨兵也参考该配置进行修改\n1 2 3 4 5 6 7 8 9 10 11 # sentinel节点端口号 port 26379 # sentinel monitor 被监控主节点名称 主节点IP 主节点端口 quorum sentinel monitor mymaster 127.0.0.1 6379 2 # sentinel down-after-milliseconds 被监控主节点名称 毫秒数 sentinel down-after-milliseconds mymaster 60000 # sentinel failover-timeout 被监控主节点名称 毫秒数 sentinel failover-timeout mymaster 180000 启动哨兵节点 1 [root@localhost redis-sentinal1]# ./src/redis-sentinel /data/redis-sentinal1/sentinel.conf 其余的哨兵节点也类似。\n验证 将master 6379 kill掉，在哨兵节点的日志中可查看到选举主节点的信息： cluster集群模式 Redis Cluster 功能 ： 负载均衡，故障切换，主从复制 。\n配置节点：\n1 2 3 4 5 6 # cluster节点端口号,从6700-6705 port 6700 # 开启集群模式 cluster-enabled yes # 节点超时时间 cluster-node-timeout 15000 分别启动各个节点：\n1 ./src/redis-server /data/redis-cluster1/redis.conf 创建cluster\n1 ./src/redis-cli -p 6700 --cluster create 127.0.0.1:6700 127.0.0.1:6701 127.0.0.1:6702 127.0.0.1:6703 127.0.0.1:6704 127.0.0.1:6705 --cluster-replicas 1 创建成功后会显示集群和节点信息。 也可通过redis客户端执行下面命令，查看集群信息\n1 cluster info 错误异常解决 如果在配置集群时，启动出现 [ERR] Node 127.0.0.1:6700 is not empty. Either the node already knows other nodes (check with CLUSTER NODES) or contains some key in database 0.。这是由于节点中存在以前旧数据导致。\n解决方式：\n停掉所有节点 删除各节点的nodes.conf 和dump.rdb文件 重新启动所有节点 重新创建集群 ","date":"2024-01-15T15:56:26+08:00","image":"https://sailingsky.github.io/p/redis%E9%9B%86%E7%BE%A4%E9%AB%98%E5%8F%AF%E7%94%A8/Logo-redis.svg_hu83de30df5e380d1440b843aa0aed1028_51229_120x120_fill_box_smart1_3.png","permalink":"https://sailingsky.github.io/p/redis%E9%9B%86%E7%BE%A4%E9%AB%98%E5%8F%AF%E7%94%A8/","title":"redis集群高可用"},{"content":"日常系统开发中，经常涉及到大数据量的业务，常见的如商城系统，规模上去后，单表会经常上千万甚至上亿。仅仅靠单表肯定是无法支撑系统的规模及性能，因此诞生了分库分表的解决方案。首先，为了保证高可用，会增加主从库备份；再者为了高性能，会利用主从库进行读写分离；为了高容量，会进行分库分表。\n整体架构图： master0和master1同为写库，用于数据分片，增加数据容量。slave0和slave1为从库，提供查询能力，分担查询压力，提升系统性能。同时作为备份库提高可靠性。\nmysql高可用集群搭建 主mysql搭建 1.docker创建主mysql服务 1 2 3 4 5 6 7 docker run -d \\ -p 3306:3306 \\ -v /data/mysql/master0/conf:/etc/mysql/conf.d \\ -v /data/mysql/master0/data:/var/lib/mysql \\ -e MYSQL_ROOT_PASSWORD=root \\ --name mysql-master \\ mysql:8.0.29 2.修改主mysql配置文件 1 vim /data/mysql/master0/conf/my.cnf 加入以下配置内容:\n1 2 3 4 5 6 7 8 9 10 11 12 [mysqld] # 服务器唯一id，默认值1 server-id=1 # 设置日志格式，默认值ROW binlog_format=STATEMENT # 二进制日志名，默认binlog # log-bin=binlog # 设置需要复制的数据库，默认复制全部数据库 #binlog-do-db=mytestdb # 设置不需要复制的数据库 #binlog-ignore-db=mysql #binlog-ignore-db=infomation_schema 重启mysql容器：\n1 docker restart mysql-master0 binlog格式说明：\nbinlog_format=STATEMENT：日志记录的是主机数据库的写指令，性能高，但是now()之类的函数以及获取系统参数的操作会出现主从数据不同步的问题。\nbinlog_format=ROW（默认）：日志记录的是主机数据库的写后的数据，批量操作时性能较差，解决now()或者 user()或者 @@hostname 等操作在主从机器上不一致的问题。\nbinlog_format=MIXED：是以上两种level的混合使用，有函数用ROW，没函数用STATEMENT，但是无法识别系统变量\n3.进入mysql主服务器，修改登录限制 1 2 3 4 5 6 #进入容器：env LANG=C.UTF-8 避免容器中显示中文乱码 docker exec -it mysql-master0 env LANG=C.UTF-8 /bin/bash #进入容器内的mysql命令行 mysql -uroot -p #修改默认密码校验方式 ALTER USER \u0026#39;root\u0026#39;@\u0026#39;%\u0026#39; IDENTIFIED WITH mysql_native_password BY \u0026#39;root\u0026#39;; 4. 创建数据复制所用的slave用户 1 2 3 4 5 6 7 CREATE USER \u0026#39;slave\u0026#39;@\u0026#39;%\u0026#39;; -- 设置密码 ALTER USER \u0026#39;slave\u0026#39;@\u0026#39;%\u0026#39; IDENTIFIED WITH mysql_native_password BY \u0026#39;root\u0026#39;; -- 授予复制权限 GRANT REPLICATION SLAVE ON *.* TO \u0026#39;slave\u0026#39;@\u0026#39;%\u0026#39;; -- 刷新权限 FLUSH PRIVILEGES; 5. 查看主mysql状态 1 show master status; 从服务器搭建 1.docker创建启动从服务器 1 2 3 4 5 6 7 docker run -d \\ -p 3307:3306 \\ -v /data/mysql/slave0/conf:/etc/mysql/conf.d \\ -v /data/mysql/slave0/data:/var/lib/mysql \\ -e MYSQL_ROOT_PASSWORD=root \\ --name mysql-slave1 \\ mysql:8.0.29 2. 修改从服务器配置 1 vim /data/mysql/slave0/conf/my.cnf 修改配置如下：\n1 2 3 4 5 [mysqld] # 服务器唯一id，每台服务器的id必须不同，如果配置其他从机，注意修改id server-id=2 # 中继日志名，默认xxxxxxxxxxxx-relay-bin #relay-log=relay-bin 重启容器：\n1 docker restart mysql-slave1 3. 修改登录方式 1 2 3 4 5 6 #进入容器： docker exec -it mysql-slave0 env LANG=C.UTF-8 /bin/bash #进入容器内的mysql命令行 mysql -uroot -p #修改默认密码校验方式 ALTER USER \u0026#39;root\u0026#39;@\u0026#39;%\u0026#39; IDENTIFIED WITH mysql_native_password BY \u0026#39;root\u0026#39;; 4. 配置主从关系 1 2 3 CHANGE MASTER TO MASTER_HOST=\u0026#39;192.168.65.131\u0026#39;, MASTER_USER=\u0026#39;slave\u0026#39;,MASTER_PASSWORD=\u0026#39;root\u0026#39;, MASTER_PORT=3306, MASTER_LOG_FILE=\u0026#39;binlog.000003\u0026#39;,MASTER_LOG_POS=1333; slave启动主从同步 1 2 3 START SLAVE; -- 查看状态（不需要分号） SHOW SLAVE STATUS\\G SpringBoot配置 pom.xml加入sharding-jdbc,mybatis-plus,mysql驱动等依赖\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;project xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\u0026#34;\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;groupId\u0026gt;com.example\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;sharding-jdbc-demo\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.0.1-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;name\u0026gt;sharding-jdbc-demo\u0026lt;/name\u0026gt; \u0026lt;description\u0026gt;sharding-jdbc-demo\u0026lt;/description\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;java.version\u0026gt;1.8\u0026lt;/java.version\u0026gt; \u0026lt;project.build.sourceEncoding\u0026gt;UTF-8\u0026lt;/project.build.sourceEncoding\u0026gt; \u0026lt;project.reporting.outputEncoding\u0026gt;UTF-8\u0026lt;/project.reporting.outputEncoding\u0026gt; \u0026lt;spring-boot.version\u0026gt;2.3.12.RELEASE\u0026lt;/spring-boot.version\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;mysql\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mysql-connector-java\u0026lt;/artifactId\u0026gt; \u0026lt;scope\u0026gt;runtime\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.baomidou\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mybatis-plus-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.3.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.projectlombok\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;lombok\u0026lt;/artifactId\u0026gt; \u0026lt;optional\u0026gt;true\u0026lt;/optional\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.shardingsphere\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;shardingsphere-jdbc-core-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.1.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-test\u0026lt;/artifactId\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;exclusions\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;groupId\u0026gt;org.junit.vintage\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;junit-vintage-engine\u0026lt;/artifactId\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;/exclusions\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;dependencyManagement\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-dependencies\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring-boot.version}\u0026lt;/version\u0026gt; \u0026lt;type\u0026gt;pom\u0026lt;/type\u0026gt; \u0026lt;scope\u0026gt;import\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;/dependencyManagement\u0026gt; \u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-compiler-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.8.1\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;source\u0026gt;1.8\u0026lt;/source\u0026gt; \u0026lt;target\u0026gt;1.8\u0026lt;/target\u0026gt; \u0026lt;encoding\u0026gt;UTF-8\u0026lt;/encoding\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring-boot.version}\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;mainClass\u0026gt;com.example.shardingjdbcdemo.ShardingJdbcDemoApplication\u0026lt;/mainClass\u0026gt; \u0026lt;skip\u0026gt;true\u0026lt;/skip\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;id\u0026gt;repackage\u0026lt;/id\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;repackage\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; \u0026lt;/project\u0026gt; application.yaml主要涉及sharding-jdbc的配置：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 server: port: 8080 spring: shardingsphere: # 内存模式 mode: type: Memory datasource: names: master0,master1,slave0,slave1 master0: type: com.zaxxer.hikari.HikariDataSource driver-class-name: com.mysql.jdbc.Driver jdbc-url: jdbc:mysql://192.168.65.131:3306/db_order username: root password: root master1: type: com.zaxxer.hikari.HikariDataSource driver-class-name: com.mysql.jdbc.Driver jdbc-url: jdbc:mysql://192.168.65.131:3308/db_order username: root password: root slave0: type: com.zaxxer.hikari.HikariDataSource driver-class-name: com.mysql.jdbc.Driver jdbc-url: jdbc:mysql://192.168.65.131:3307/db_order username: root password: root slave1: type: com.zaxxer.hikari.HikariDataSource driver-class-name: com.mysql.jdbc.Driver jdbc-url: jdbc:mysql://192.168.65.131:3309/db_order username: root password: root #sql日志输出 props: sql-show: true rules: # 读写分离配置 readwrite-splitting: data-sources: rwds0: type: Static props: #写数据源名称 write-data-source-name: master0 #读数据源名称 read-data-source-names: slave0 # 负载均衡算法名称 load-balancer-name: alg_round rwds1: type: Static props: #写数据源名称 write-data-source-name: master1 #读数据源名称 read-data-source-names: slave1 # 负载均衡算法名称 load-balancer-name: alg_round # 负载均衡算法类型 load-balancers: alg_round: type: RANDOM # 分片配置 sharding: tables: t_order: actual-data-nodes: rwds$-\u0026gt;{0..1}.t_order$-\u0026gt;{0..1} # 分库策略 database-strategy: standard: # 分片列名称 sharding-column: user_id #分片算法名称 sharding-algorithm-name: alg_mod # 分表策略 table-strategy: standard: sharding-column: id sharding-algorithm-name: alg_mod #分布式序列策略配置 key-generate-strategy: column: id key-generator-name: alg_snowflake sharding-algorithms: # 分片算法取余，按分片数2取余 alg_mod: type: mod props: sharding-count: 2 #主键生成策略 key-generators: alg_snowflake: type: SNOWFLAKE 测试代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 package com.example.shardingjdbcdemo; import com.example.shardingjdbcdemo.entity.Order; import com.example.shardingjdbcdemo.mapper.OrderMapper; import org.junit.jupiter.api.Test; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.boot.test.context.SpringBootTest; import java.math.BigDecimal; import java.util.List; /** * @Author: * @Date: 2024-01-09 17:55 */ @SpringBootTest public class ShardingTest { @Autowired OrderMapper orderMapper; @Test public void testInsertOrder(){ for(int i =0;i\u0026lt;5;i++){ Order order = new Order(); order.setOrderNo(\u0026#34;sn20231011\u0026#34;); order.setUserId(Long.valueOf(i+1)); order.setAmount(BigDecimal.valueOf(2.22)); orderMapper.insert(order); } } @Test public void query(){ List\u0026lt;Order\u0026gt; orders = orderMapper.selectList(null); List\u0026lt;Order\u0026gt; orders1 = orderMapper.selectList(null); List\u0026lt;Order\u0026gt; orders2 = orderMapper.selectList(null); List\u0026lt;Order\u0026gt; orders3 = orderMapper.selectList(null); } } 可从插入数据查看到对应主从库及分片数据的存储，查询也可根据控制台打印的sql，看到数据的查询走的从库了，分担了主库的压力。\n当然，你还可以根据上面的架构，改造成一主多从，实现水平分库分表，多从库读的能力。\n","date":"2024-01-09T21:14:46+08:00","image":"https://sailingsky.github.io/post/java/sharding-jdbc/pexels-google-deepmind-17483874.jpg","permalink":"https://sailingsky.github.io/p/sharding-jdbc%E5%AE%9E%E7%8E%B0%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB-%E6%B0%B4%E5%B9%B3%E5%88%86%E7%89%87/","title":"Sharding Jdbc实现读写分离+水平分片"},{"content":"websocket相关配置： 新建了个websocket-server模块微服务。\n引入websocket依赖： 1 2 3 4 5 \u0026lt;!-- websocket --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-websocket\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 加入配置代码：\n1 2 3 4 5 6 7 8 @Configuration public class WebSocketConfig { @Bean public ServerEndpointExporter serverEndpointExporter(){ return new ServerEndpointExporter(); } } 加入服务接口逻辑：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 @ServerEndpoint(\u0026#34;/ws/alert/{userId}\u0026#34;) @Component @Slf4j public class WebSocketServer { /** * concurrent包的线程安全Set，用来存放每个客户端对应的MyWebSocket对象。 */ private static ConcurrentHashMap\u0026lt;String, WebSocketServer\u0026gt; webSocketMap = new ConcurrentHashMap\u0026lt;\u0026gt;(); /** * 与某个客户端的连接会话，需要通过它来给客户端发送数据 */ private Session session; /** * 接收userId */ private String userId = \u0026#34;\u0026#34;; /** * 连接建立成功调用的方法 */ @OnOpen public void onOpen(Session session, @PathParam(\u0026#34;userId\u0026#34;) String userId) { this.session = session; this.userId = userId; if (webSocketMap.containsKey(userId)) { webSocketMap.remove(userId); } webSocketMap.put(userId, this); log.info(\u0026#34;用户连接:{}\u0026#34; , userId ); } /** * 连接关闭调用的方法 */ @OnClose public void onClose() { if (webSocketMap.containsKey(userId)) { webSocketMap.remove(userId); } log.info(\u0026#34;用户退出:{}\u0026#34; + userId); } /** * 收到客户端消息后调用的方法 * * @param message 客户端发送过来的消息 */ @OnMessage public void onMessage(String message, Session session) { log.info(\u0026#34;收到用户消息:{},报文:{}\u0026#34; , userId ,message); } /** * @param session * @param error */ @OnError public void onError(Session session, Throwable error) { log.error(\u0026#34;用户错误:\u0026#34; + this.userId + \u0026#34;,原因:\u0026#34; + error.getMessage()); error.printStackTrace(); } /** * 实现服务器主动推送 */ public void sendMessage(String message) { webSocketMap.forEach((key, webSocketServer) -\u0026gt; { try { webSocketServer.session.getBasicRemote().sendText(message); } catch (IOException e) { throw new RuntimeException(e); } }); } } gateway配置： application.yml加入路由配置：\n1 2 3 4 5 6 7 8 9 10 gateway: routes: - id: wsroute # uri: ws://websocket-server uri: ws://localhost:10119 predicates: - Path=/websocket-server/ws/** - Header=Connection,Upgrade filters: - StripPrefix=1 趟坑排雷： 当你觉得万无一失，启动相关服务进行调试请求的时候，问题就来了：\nio.undertow.server.HttpServerExchange cannot be cast to reactor.netty.http.server.HttpServerResponse 异常 完整异常堆栈信息如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 java.lang.ClassCastException: io.undertow.server.HttpServerExchange cannot be cast to reactor.netty.http.server.HttpServerResponse at org.springframework.web.reactive.socket.server.upgrade.ReactorNettyRequestUpgradeStrategy.upgrade(ReactorNettyRequestUpgradeStrategy.java:163) Suppressed: reactor.core.publisher.FluxOnAssembly$OnAssemblyException: Error has been observed at the following site(s): *__checkpoint ⇢ org.springframework.cloud.gateway.filter.WeightCalculatorWebFilter [DefaultWebFilterChain] *__checkpoint ⇢ HTTP GET \u0026#34;/websocket-server/ws/alert/1\u0026#34; [ExceptionHandlingWebHandler] Original Stack Trace: at org.springframework.web.reactive.socket.server.upgrade.ReactorNettyRequestUpgradeStrategy.upgrade(ReactorNettyRequestUpgradeStrategy.java:163) at org.springframework.web.reactive.socket.server.support.HandshakeWebSocketService.lambda$handleRequest$1(HandshakeWebSocketService.java:243) at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:152) at reactor.core.publisher.MonoFlatMap.subscribeOrReturn(MonoFlatMap.java:53) at reactor.core.publisher.InternalMonoOperator.subscribe(InternalMonoOperator.java:57) at reactor.core.publisher.MonoDefer.subscribe(MonoDefer.java:52) at reactor.core.publisher.MonoDefer.subscribe(MonoDefer.java:52) at reactor.core.publisher.MonoIgnoreThen$ThenIgnoreMain.subscribeNext(MonoIgnoreThen.java:236) at reactor.core.publisher.MonoIgnoreThen$ThenIgnoreMain.onComplete(MonoIgnoreThen.java:203) at reactor.core.publisher.FluxPeek$PeekSubscriber.onComplete(FluxPeek.java:260) at reactor.core.publisher.FluxMap$MapSubscriber.onComplete(FluxMap.java:142) at reactor.core.publisher.MonoNext$NextSubscriber.onComplete(MonoNext.java:102) at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:83) at reactor.core.publisher.FluxDematerialize$DematerializeSubscriber.onNext(FluxDematerialize.java:98) at reactor.core.publisher.FluxDematerialize$DematerializeSubscriber.onNext(FluxDematerialize.java:44) at reactor.core.publisher.FluxFlattenIterable$FlattenIterableSubscriber.drainAsync(FluxFlattenIterable.java:421) at reactor.core.publisher.FluxFlattenIterable$FlattenIterableSubscriber.drain(FluxFlattenIterable.java:686) at reactor.core.publisher.FluxFlattenIterable$FlattenIterableSubscriber.onNext(FluxFlattenIterable.java:250) at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onNext(FluxSwitchIfEmpty.java:74) at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816) at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249) at reactor.core.publisher.MonoIgnoreThen$ThenIgnoreMain.complete(MonoIgnoreThen.java:284) at reactor.core.publisher.MonoIgnoreThen$ThenIgnoreMain.onNext(MonoIgnoreThen.java:187) at reactor.core.publisher.MonoIgnoreThen$ThenIgnoreMain.subscribeNext(MonoIgnoreThen.java:232) at reactor.core.publisher.MonoIgnoreThen$ThenIgnoreMain.onComplete(MonoIgnoreThen.java:203) at reactor.core.publisher.MonoIgnoreElements$IgnoreElementsSubscriber.onComplete(MonoIgnoreElements.java:89) at reactor.core.publisher.FluxPeek$PeekSubscriber.onComplete(FluxPeek.java:260) at reactor.core.publisher.FluxDematerialize$DematerializeSubscriber.onComplete(FluxDematerialize.java:121) at reactor.core.publisher.FluxDematerialize$DematerializeSubscriber.onNext(FluxDematerialize.java:91) at reactor.core.publisher.FluxDematerialize$DematerializeSubscriber.onNext(FluxDematerialize.java:44) at reactor.core.publisher.FluxIterable$IterableSubscription.fastPath(FluxIterable.java:340) at reactor.core.publisher.FluxIterable$IterableSubscription.request(FluxIterable.java:227) at reactor.core.publisher.FluxDematerialize$DematerializeSubscriber.request(FluxDematerialize.java:127) at reactor.core.publisher.FluxPeek$PeekSubscriber.request(FluxPeek.java:138) at reactor.core.publisher.MonoIgnoreElements$IgnoreElementsSubscriber.onSubscribe(MonoIgnoreElements.java:72) at reactor.core.publisher.FluxPeek$PeekSubscriber.onSubscribe(FluxPeek.java:171) at reactor.core.publisher.FluxDematerialize$DematerializeSubscriber.onSubscribe(FluxDematerialize.java:77) at reactor.core.publisher.FluxIterable.subscribe(FluxIterable.java:165) at reactor.core.publisher.FluxIterable.subscribe(FluxIterable.java:87) at reactor.core.publisher.Mono.subscribe(Mono.java:4400) at reactor.core.publisher.MonoIgnoreThen$ThenIgnoreMain.subscribeNext(MonoIgnoreThen.java:255) at reactor.core.publisher.MonoIgnoreThen.subscribe(MonoIgnoreThen.java:51) at reactor.core.publisher.MonoFlatMap$FlatMapMain.onNext(MonoFlatMap.java:157) at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816) at reactor.core.publisher.MonoCollectList$MonoCollectListSubscriber.onComplete(MonoCollectList.java:128) at reactor.core.publisher.DrainUtils.postCompleteDrain(DrainUtils.java:132) at reactor.core.publisher.DrainUtils.postComplete(DrainUtils.java:187) at reactor.core.publisher.FluxMaterialize$MaterializeSubscriber.onComplete(FluxMaterialize.java:141) at reactor.core.publisher.FluxTake$TakeSubscriber.onComplete(FluxTake.java:153) at reactor.core.publisher.FluxTake$TakeSubscriber.onNext(FluxTake.java:133) at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onNext(FluxOnErrorResume.java:79) at reactor.core.publisher.SerializedSubscriber.onNext(SerializedSubscriber.java:99) at reactor.core.publisher.FluxTimeout$TimeoutMainSubscriber.onNext(FluxTimeout.java:180) at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816) at reactor.core.publisher.MonoCollectList$MonoCollectListSubscriber.onComplete(MonoCollectList.java:128) at org.springframework.cloud.commons.publisher.FluxFirstNonEmptyEmitting$FirstNonEmptyEmittingSubscriber.onComplete(FluxFirstNonEmptyEmitting.java:325) at reactor.core.publisher.FluxSubscribeOn$SubscribeOnSubscriber.onComplete(FluxSubscribeOn.java:166) at reactor.core.publisher.FluxIterable$IterableSubscription.fastPath(FluxIterable.java:362) at reactor.core.publisher.FluxIterable$IterableSubscription.request(FluxIterable.java:227) at reactor.core.publisher.FluxSubscribeOn$SubscribeOnSubscriber.requestUpstream(FluxSubscribeOn.java:131) at reactor.core.publisher.FluxSubscribeOn$SubscribeOnSubscriber.onSubscribe(FluxSubscribeOn.java:124) at reactor.core.publisher.FluxIterable.subscribe(FluxIterable.java:165) at reactor.core.publisher.FluxIterable.subscribe(FluxIterable.java:87) at reactor.core.publisher.Flux.subscribe(Flux.java:8469) at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:200) at reactor.core.publisher.MonoFlatMapMany.subscribeOrReturn(MonoFlatMapMany.java:49) at reactor.core.publisher.Flux.subscribe(Flux.java:8455) at reactor.core.publisher.FluxFlatMap.trySubscribeScalarMap(FluxFlatMap.java:200) at reactor.core.publisher.MonoFlatMapMany.subscribeOrReturn(MonoFlatMapMany.java:49) at reactor.core.publisher.FluxFromMonoOperator.subscribe(FluxFromMonoOperator.java:76) at reactor.core.publisher.FluxSubscribeOn$SubscribeOnSubscriber.run(FluxSubscribeOn.java:194) at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:84) at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:37) at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266) at java.util.concurrent.FutureTask.run(FutureTask.java) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:750) 好了，有异常，咱们网上找找答案，可在网上翻了大半天，发现没几个答案，绝大部分说的都是啥移除tomcat依赖springcloud gateway+websocket使用的坑，实际上尝试了并不行。后面翻到了博客园上这哥们的文章springCloudGateway-踩坑记录,在文章的后面，有相同的异常报错，但是哥们直接换了nginx来转发了，不走gateway了。囧。\n升级版本试试\n看了下gateway用的版本3.1.1，心想如果升级下就能成功了呢。于是本地搞了demo，把spring boot,spring cloud以及jdk咔咔一顿升级，最后用了\n1 JDK：17；spring-boot-starter-parent：3.1.5 ；spring-cloud-dependencies：2022.0.4；spring-cloud-starter-gateway：4.0.7 期待着会有奇迹发生。然而并没有。接着出现了java.lang.ClassCastException: class org.apache.catalina.connector.ResponseFacade cannot be cast to class reactor.netty.http.server.HttpServerResponse (org.apache.catalina.connector.ResponseFacade and reactor.netty.http.server.HttpServerResponse are in unnamed module of loader 'app') 这个异常。\n这个异常好找，在github中找到了答案websocket connction question ,需要加入以下bean的配置：\n1 2 3 4 5 6 7 8 9 10 11 @Bean @Primary public RequestUpgradeStrategy requestUpgradeStrategy() { return new TomcatRequestUpgradeStrategy(); } @Bean @Primary WebSocketClient tomcatWebSocketClient() { return new TomcatWebSocketClient(); } 加了重新启动，发现好使了，能成功链接访问了。\nnacos负载均衡 在仔细看看之前的gateway配置，是没进行负载均衡配置的，直接固定转给某个websocket服务。环境上是需要负载均衡配置的，因此改个配置试试。\n1 2 3 4 5 6 7 8 routes: - id: wsroute uri: lb:ws://websocket-server predicates: - Path=/websocket-server/ws/** - Header=Connection,Upgrade filters: - StripPrefix=1 当启动后，发现又不好使了，报了503异常，原来是忘了加入feign相关组件依赖：\n1 2 3 4 5 6 7 8 9 10 \u0026lt;!--fegin组件--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-openfeign\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- Feign Client for loadBalancing --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-loadbalancer\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; ","date":"2023-11-22T16:45:23+08:00","image":"https://sailingsky.github.io/p/spring-cloud-gateway%E8%BD%AC%E5%8F%91websocket%E8%AF%B7%E6%B1%82/chris-rosiak-YSwcI_rmCYo-unsplash_hu3d03a01dcc18bc5be0e67db3d8d209a6_5726551_120x120_fill_q75_box_smart1.jpg","permalink":"https://sailingsky.github.io/p/spring-cloud-gateway%E8%BD%AC%E5%8F%91websocket%E8%AF%B7%E6%B1%82/","title":"Spring cloud gateway转发websocket请求"},{"content":"目前很多应用开发部署都是基于Docker容器化，为了简化本地开发测试，可以在idea中进行相关配置，即可实现本地打包部署高效率。\n前置条件 装有Docker的服务器 Idea Docker服务器配置 修改/usr/lib/systemd/system/docker.service配置： 1 vi /usr/lib/systemd/system/docker.service 在配置项ExecStart中加入 -H tcp://0.0.0.0:10086： 配置完成后记得重启docker\n1 2 systemctl daemon-reload systemctl restart docker 顺便记得确认防火墙，相关端口记得开放：\n1 2 3 4 5 firewall-cmd --zone=public --add-port=10086/tcp --permanent firewall-cmd --reload #查看开放的端口 firewall-cmd --list-all idea配置: settings-\u0026gt;Build-\u0026gt;Docker新增docker配置，输入docker服务所在ip及之前配置的端口 配置Docker Registry,这步作用是方便拉取镜像打包时所依赖的其他镜像，如不配置国内镜像源，会容易出现镜像拉取失败：\n建立示例工程测试： idea中建个springboot工程，此步骤简单略过。\n修改pom.xml文件，加入plugin,dockerHost属性配置之前定义好的:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;com.spotify\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;docker-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.2.2\u0026lt;/version\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;id\u0026gt;build-image\u0026lt;/id\u0026gt; \u0026lt;phase\u0026gt;package\u0026lt;/phase\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;build\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;dockerHost\u0026gt;http://192.168.65.131:2375\u0026lt;/dockerHost\u0026gt; \u0026lt;imageName\u0026gt;zsj/${project.artifactId}\u0026lt;/imageName\u0026gt; \u0026lt;imageTags\u0026gt; \u0026lt;imageTag\u0026gt;${project.version}\u0026lt;/imageTag\u0026gt; \u0026lt;/imageTags\u0026gt; \u0026lt;forceTags\u0026gt;true\u0026lt;/forceTags\u0026gt; \u0026lt;dockerDirectory\u0026gt;${project.basedir}\u0026lt;/dockerDirectory\u0026gt; \u0026lt;resources\u0026gt; \u0026lt;resource\u0026gt; \u0026lt;targetPath\u0026gt;/\u0026lt;/targetPath\u0026gt; \u0026lt;directory\u0026gt;${project.build.directory}\u0026lt;/directory\u0026gt; \u0026lt;include\u0026gt;${project.build.finalName}.jar\u0026lt;/include\u0026gt; \u0026lt;/resource\u0026gt; \u0026lt;/resources\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; 工程根目录新增Dockerfile:\n1 2 3 4 FROM openjdk:8-jdk-alpine ARG JAR_FILE=target/*.jar COPY ${JAR_FILE} app.jar ENTRYPOINT [\u0026#34;java\u0026#34;,\u0026#34;-jar\u0026#34;,\u0026#34;/app.jar\u0026#34;] 运行maven的package任务：\n成功后可在控制台看到如下输出：\n登录docker所在服务器，查看镜像是否打包上传成功：\n","date":"2023-11-14T11:16:14+08:00","image":"https://sailingsky.github.io/p/idea%E6%9E%84%E5%BB%BA%E6%89%93%E5%8C%85%E4%B8%8A%E4%BC%A0docker%E9%95%9C%E5%83%8F/5-maniere-deplacer-conteneur-docker-vers-autre-machine_hu5e9a2feb3483bf40d57feb14e1a23a14_88760_120x120_fill_q75_box_smart1.jpeg","permalink":"https://sailingsky.github.io/p/idea%E6%9E%84%E5%BB%BA%E6%89%93%E5%8C%85%E4%B8%8A%E4%BC%A0docker%E9%95%9C%E5%83%8F/","title":"Idea构建打包上传Docker镜像"},{"content":"题目定义： 给定一个不含重复数字的数组 nums ，返回其 所有可能的全排列 。你可以 按任意顺序 返回答案。\n示例 1：\n输入：nums = [1,2,3] 输出：[[1,2,3],[1,3,2],[2,1,3],[2,3,1],[3,1,2],[3,2,1]] 示例 2：\n输入：nums = [0,1] 输出：[[0,1],[1,0]] 示例 3：\n输入：nums = [1] 输出：[[1]]\n整体算法思路： 采用回溯算法，遍历循环数组，形成路径，每一层中循环的都是数组的所有元素，为了不使元素重复，加入额外的存储空间存储判断。\n题解： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 public List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; permute(int[] nums) { //存储最终结果 List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; result = new ArrayList\u0026lt;\u0026gt;(); //临时存储数组中元素是否已被当前路径使用 boolean[] used = new boolean[nums.length]; //路径 LinkedList\u0026lt;Integer\u0026gt; path = new LinkedList\u0026lt;\u0026gt;(); backTrace(path,used,nums,result); return result; } public void backTrace(LinkedList\u0026lt;Integer\u0026gt; path,boolean[] used,int[] nums,List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; result){ //当这条路径元素数和数组大小一致时，说明该条路径已走完，存储结果并返回 if (path.size()==nums.length) { result.add(new ArrayList\u0026lt;\u0026gt;(path)); return; } for(int i = 0;i\u0026lt; nums.length;i++){ //当数组元素标记被使用，跳过 if(used[i]) continue; //将元素加入路径中 path.add(nums[i]); //标记元素被使用 used[i] = true; //回溯往下选择路径 backTrace(path,used,nums,result); //往回撤销选择 used[i] =false; //去除路径中已选择的元素 path.removeLast(); } } ","date":"2023-11-13T17:30:56+08:00","image":"https://sailingsky.github.io/post/algorithm/pexels-google-deepmind-18069816.jpg","permalink":"https://sailingsky.github.io/p/%E5%85%A8%E6%8E%92%E5%88%97/","title":"全排列"},{"content":"起因 最近因工作需要，需要调用grpc服务的一个接口，以前也没接触过，接口提供方呢就扔了个proto文件过来，没法，在网上到处翻翻找找，说的都比较杂乱，缺少部分细节，就简单写个文章记录下吧。\n具体细节 引入proto文件 在工程\\src\\main目录下新建proto目录，将服务提供方提供的proto文件放入该目录。\npom.xml文件引入依赖及maven插件：\n1 2 3 4 5 6 \u0026lt;!-- grpc client --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;net.devh\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;grpc-client-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.14.0.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; maven插件：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 \u0026lt;extensions\u0026gt; \u0026lt;!-- os-maven-plugin 插件，从 OS 系统中获取参数 --\u0026gt; \u0026lt;extension\u0026gt; \u0026lt;groupId\u0026gt;kr.motd.maven\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;os-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.5.0.Final\u0026lt;/version\u0026gt; \u0026lt;/extension\u0026gt; \u0026lt;/extensions\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;!-- protobuf-maven-plugin 插件，通过 protobuf 文件，生成 Service 和 Message 类 --\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.xolstice.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;protobuf-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.5.1\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;pluginId\u0026gt;grpc-java\u0026lt;/pluginId\u0026gt; \u0026lt;protocArtifact\u0026gt;com.google.protobuf:protoc:3.5.1:exe:${os.detected.classifier} \u0026lt;/protocArtifact\u0026gt; \u0026lt;pluginArtifact\u0026gt;io.grpc:protoc-gen-grpc-java:1.51.0:exe:${os.detected.classifier} \u0026lt;/pluginArtifact\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;compile\u0026lt;/goal\u0026gt; \u0026lt;goal\u0026gt;compile-custom\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; application.yaml中添加grpc配置：\n1 2 3 4 5 6 7 grpc: client: grpc-client: address: \u0026#39;static://${grpc服务地址}\u0026#39; enableKeepAlive: true keepAliveWithoutCalls: true negotiationType: plaintext 跑mvn compile任务，将protobuf文件生成对应的Java代码\n在业务代码中调用grpc服务：\n1 2 3 4 5 6 7 8 @GrpcClient(\u0026#34;grpc-client\u0026#34;) private xxGrpc.xxBlockingStub xxStub; public boolean sync(){ Request.SyncRequest request = Request.SyncRequest.newBuilder().setType(\u0026#34;sync\u0026#34;).build(); Response.CommonResponse commonResponse = xxStub.syncRulesHandler(request); return commonResponse.getCode()==0; } 验证grpc服务：\n如果只是想单纯验证下grpc服务是否正常，可以用postman进行操作。\n选择请求类型grpc：\n导入protobuf文件：\n接着就可以输入grpc服务地址及对应参数进行测试了。\n","date":"2023-11-09T11:06:11+08:00","image":"https://sailingsky.github.io/p/spring-boot-%E8%B0%83%E7%94%A8grpc/steve-busch-b_nBSjoGtrU-unsplash_hu3d03a01dcc18bc5be0e67db3d8d209a6_1755468_120x120_fill_q75_box_smart1.jpg","permalink":"https://sailingsky.github.io/p/spring-boot-%E8%B0%83%E7%94%A8grpc/","title":"Spring boot 调用Grpc"},{"content":"斐波那契数列定义： 引用自维基百科：\n斐波那契数（意大利语：Successione di Fibonacci），又译为菲波拿契数、菲波那西数、斐氏数、黄金分割数。所形成的数列称为斐波那契数列（意大利语：Successione di Fibonacci），又译为菲波拿契数列、菲波那西数列、斐氏数列、黄金分割数列。这个数列是由意大利数学家斐波那契在他的《算盘书》中提出。\n在数学上，斐波那契数是以递归的方法来定义：\n（) 用文字来说，就是斐波那契数列由0和1开始，之后的斐波那契数就是由之前的两数相加而得出。\n递归解法1： 根据其数学定义，采用递归方式，直译成代码：\n1 2 3 4 static int fib1(int n){ if(n==0||n==1) return n; return fib1(n-1)+fib1(n-2); } 此种方式简单明了，但运行起来会发现，随着n的增大，其耗时也随着增大变慢。其中原因在于会重复计算，如n=40时，第一次递归时计算f(39)和f(38)，第二次递归时计算f(38),f(37)以及f(37)和f(36)。为了加快效率，我们可以加入个临时存储空间，将计算过的结果存放与此。\n递归临时存储： 运用数组存放已计算过的结果，数组长度为n+1;\n1 2 3 4 5 6 7 static int fibWithArrayTemp(int n,int[] temp){ if(n==0||n==1) return n; //如果该位置非0，说明已经存在计算结果 if(temp[n]!=0) return temp[n]; temp[n] = fibWithArrayTemp(n-1,temp)+fibWithArrayTemp(n-2,temp); return temp[n]; } 动态规划解法： 以上解法都是利用递归，从上往下进行，采用动态规划，由下往上进行计算。辅助数组dptable用于存储计算过程中产生的结果。\n1 2 3 4 5 6 7 8 9 static int fibWithDP(int n){ if(n==0) return 0; int[] dptable = new int[n+1]; dptable[0]=0;dptable[1]=1; for(int i=2;i\u0026lt;=n;i++){ dptable[i] = dptable[i-1]+dptable[i-2]; } return dptable[n]; } 动态规划解法-优化： 上面的都是通过创建n+1个元素数组，作为临时结果存储。空间复杂度为O(N),那还有没有可能优化一下。当然是可以的，我们可以找出规律，发现有用的都是前两个结果元素，可以只用两个变量存储即可，这样能将空间复杂度降为O(1)。\n1 2 3 4 5 6 7 8 9 10 11 12 13 static int fibWithDPOpt(int n ){ if(n==0) return 0; //前后两个元素 int pre= 0,post = 1 ; int result = 0; for(int i=2;i\u0026lt;=n;i++){ result = pre+post; //滚动更新前后两个元素结果 pre = post; post = result; } return result; } ","date":"2023-09-25T10:52:14+08:00","image":"https://sailingsky.github.io/post/algorithm/pexels-google-deepmind-18069816.jpg","permalink":"https://sailingsky.github.io/p/%E6%96%90%E6%B3%A2%E9%82%A3%E5%A5%91%E6%95%B0%E5%88%97%E8%A7%A3%E6%B3%95/","title":"斐波那契数列解法"},{"content":"下载安装hugo 去github上下载对应系统的安装包：hugo安装包。由于我是windows系统，那就下载windows版本。 下载完成后，解压将安装文件放至到某个目录。修改环境变量path,添加刚才hugo文件所在路径。 命令行验证是否本地安装成功： 创建Github仓库 创建博客源文件内容仓库： 名字随意取 创建GitHub Pages仓库： 仓库名称必须使用\u0026lt;username.github.io\u0026gt;的格式，username为GitHub的用户名: ~~### 将博客源文件内容仓库拉到本地：\n1 git clone https://github.com/username/blog.git ~~### 用hugo创建网站：\n进入刚下的本地仓库文件夹，如blog 使用命令hugo new site 网站名称创建网站。 1 2 cd blog hugo new site bytecode-blog ~~### 安装和配置hugo主题\n进入到之前的myblog目录，根据选择的hugo主题安装文件，我这里选择的是stack主题：\n1 git submodule add https://github.com/CaiJimmy/hugo-theme-stack/ themes/hugo-theme-stack ~~### 配置主题\n将themes\\hugo-theme-stack\\exampleSite里面的content文件以及config.yaml拷贝覆盖到根目录下\n更简单的作法，前面删除线的步骤皆可不用！ 如果确定使用stack主题，直接去GitHub下载stack-starter工程。 修改config\\_default目录下的config.toml文件，将baseurl修改为：https://\u0026lt;github-username\u0026gt;.github.io/ 运行hugo server命令，即可在本地看到效果。 运行hugo命令，将生成对应的静态文件。在public文件夹下。 进入到public文件夹，执行以下命令,将静态文件上传到Github： 1 2 3 4 5 6 7 8 9 10 11 git init -b main git remote add origin git@github.com:\u0026lt;github-username\u0026gt;/\u0026lt;github-username\u0026gt;.github.io.git git pull --rebase origin main git add . git commit -m \u0026#39;message\u0026#39; git push origin main 查看效果： 接着你就可以访问https://\u0026lt;github-username\u0026gt;.github.io查看效果了： ","date":"2023-09-17T18:07:30+08:00","image":"https://sailingsky.github.io/p/build-blog/cover_hu3d03a01dcc18bc5be0e67db3d8d209a6_790554_120x120_fill_q75_box_smart1.jpg","permalink":"https://sailingsky.github.io/p/build-blog/","title":"Build Blog"},{"content":"This article offers a sample of basic Markdown syntax that can be used in Hugo content files, also it shows whether basic HTML elements are decorated with CSS in a Hugo theme.\nHeadings The following HTML \u0026lt;h1\u0026gt;—\u0026lt;h6\u0026gt; elements represent six levels of section headings. \u0026lt;h1\u0026gt; is the highest section level while \u0026lt;h6\u0026gt; is the lowest.\nH1 H2 H3 H4 H5 H6 Paragraph Xerum, quo qui aut unt expliquam qui dolut labo. Aque venitatiusda cum, voluptionse latur sitiae dolessi aut parist aut dollo enim qui voluptate ma dolestendit peritin re plis aut quas inctum laceat est volestemque commosa as cus endigna tectur, offic to cor sequas etum rerum idem sintibus eiur? Quianimin porecus evelectur, cum que nis nust voloribus ratem aut omnimi, sitatur? Quiatem. Nam, omnis sum am facea corem alique molestrunt et eos evelece arcillit ut aut eos eos nus, sin conecerem erum fuga. Ri oditatquam, ad quibus unda veliamenimin cusam et facea ipsamus es exerum sitate dolores editium rerore eost, temped molorro ratiae volorro te reribus dolorer sperchicium faceata tiustia prat.\nItatur? Quiatae cullecum rem ent aut odis in re eossequodi nonsequ idebis ne sapicia is sinveli squiatum, core et que aut hariosam ex eat.\nBlockquotes The blockquote element represents content that is quoted from another source, optionally with a citation which must be within a footer or cite element, and optionally with in-line changes such as annotations and abbreviations.\nBlockquote without attribution Tiam, ad mint andaepu dandae nostion secatur sequo quae. Note that you can use Markdown syntax within a blockquote.\nBlockquote with attribution Don\u0026rsquo;t communicate by sharing memory, share memory by communicating.\n— Rob Pike1\nTables Tables aren\u0026rsquo;t part of the core Markdown spec, but Hugo supports supports them out-of-the-box.\nName Age Bob 27 Alice 23 Inline Markdown within tables Italics Bold Code italics bold code A B C D E F Lorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus ultricies, sapien non euismod aliquam, dui ligula tincidunt odio, at accumsan nulla sapien eget ex. Proin eleifend dictum ipsum, non euismod ipsum pulvinar et. Vivamus sollicitudin, quam in pulvinar aliquam, metus elit pretium purus Proin sit amet velit nec enim imperdiet vehicula. Ut bibendum vestibulum quam, eu egestas turpis gravida nec Sed scelerisque nec turpis vel viverra. Vivamus vitae pretium sapien Code Blocks Code block with backticks 1 2 3 4 5 6 7 8 9 10 \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Code block indented with four spaces \u0026lt;!doctype html\u0026gt;\r\u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt;\r\u0026lt;head\u0026gt;\r\u0026lt;meta charset=\u0026quot;utf-8\u0026quot;\u0026gt;\r\u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt;\r\u0026lt;/head\u0026gt;\r\u0026lt;body\u0026gt;\r\u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt;\r\u0026lt;/body\u0026gt;\r\u0026lt;/html\u0026gt;\rDiff code block 1 2 3 4 5 [dependencies.bevy] git = \u0026#34;https://github.com/bevyengine/bevy\u0026#34; rev = \u0026#34;11f52b8c72fc3a568e8bb4a4cd1f3eb025ac2e13\u0026#34; - features = [\u0026#34;dynamic\u0026#34;] + features = [\u0026#34;jpeg\u0026#34;, \u0026#34;dynamic\u0026#34;] One line code block 1 \u0026lt;p\u0026gt;A paragraph\u0026lt;/p\u0026gt; List Types Ordered List First item Second item Third item Unordered List List item Another item And another item Nested list Fruit Apple Orange Banana Dairy Milk Cheese Other Elements — abbr, sub, sup, kbd, mark GIF is a bitmap image format.\nH2O\nXn + Yn = Zn\nPress CTRL + ALT + Delete to end the session.\nMost salamanders are nocturnal, and hunt for insects, worms, and other small creatures.\nThe above quote is excerpted from Rob Pike\u0026rsquo;s talk during Gopherfest, November 18, 2015.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2023-09-07T00:00:00Z","permalink":"https://sailingsky.github.io/p/markdown-syntax-guide/","title":"Markdown Syntax Guide"},{"content":"Hugo theme Stack supports the creation of interactive image galleries using Markdown. It\u0026rsquo;s powered by PhotoSwipe and its syntax was inspired by Typlog.\nTo use this feature, the image must be in the same directory as the Markdown file, as it uses Hugo\u0026rsquo;s page bundle feature to read the dimensions of the image. External images are not supported.\nSyntax 1 ![Image 1](1.jpg) ![Image 2](2.jpg) Result Photo by mymind and Luke Chesser on Unsplash\n","date":"2023-08-26T00:00:00Z","image":"https://sailingsky.github.io/p/image-gallery/2_hubce42636ecacc1a380b462f3110efcec_37455_120x120_fill_q75_box_smart1.jpg","permalink":"https://sailingsky.github.io/p/image-gallery/","title":"Image gallery"},{"content":"For more details, check out the documentation.\nBilibili video Tencent video YouTube video Generic video file Your browser doesn't support HTML5 video. Here is a link to the video instead. Gist GitLab Quote Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n― A famous person, The book they wrote Photo by Codioful on Unsplash\n","date":"2023-08-25T00:00:00Z","image":"https://sailingsky.github.io/p/shortcodes/cover_huec3c3e34981507583e214021ad1b9a4b_12942_120x120_fill_q75_box_smart1.jpg","permalink":"https://sailingsky.github.io/p/shortcodes/","title":"Shortcodes"},{"content":"Stack has built-in support for math typesetting using KaTeX.\nIt\u0026rsquo;s not enabled by default side-wide, but you can enable it for individual posts by adding math: true to the front matter. Or you can enable it side-wide by adding math = true to the params.article section in config.toml.\nInline math This is an inline mathematical expression: $\\varphi = \\dfrac{1+\\sqrt5}{2}= 1.6180339887…$\n1 $\\varphi = \\dfrac{1+\\sqrt5}{2}= 1.6180339887…$ Block math $$ \\varphi = 1+\\frac{1} {1+\\frac{1} {1+\\frac{1} {1+\\cdots} } } $$\n1 2 3 $$ \\varphi = 1+\\frac{1} {1+\\frac{1} {1+\\frac{1} {1+\\cdots} } } $$ $$ f(x) = \\int_{-\\infty}^\\infty\\hat f(\\xi),e^{2 \\pi i \\xi x},d\\xi $$\n1 2 3 $$ f(x) = \\int_{-\\infty}^\\infty\\hat f(\\xi)\\,e^{2 \\pi i \\xi x}\\,d\\xi $$ ","date":"2023-08-24T00:00:00Z","permalink":"https://sailingsky.github.io/p/math-typesetting/","title":"Math Typesetting"},{"content":"Welcome to Hugo theme Stack. This is your first post. Edit or delete it, then start writing!\nFor more information about this theme, check the documentation: https://stack.jimmycai.com/\nWant a site like this? Check out hugo-theme-stack-stater\nPhoto by Pawel Czerwinski on Unsplash\n","date":"2022-03-06T00:00:00Z","image":"https://sailingsky.github.io/p/hello-world/cover_hud7e36f7e20e71be184458283bdae4646_55974_120x120_fill_q75_box_smart1.jpg","permalink":"https://sailingsky.github.io/p/hello-world/","title":"Hello World"}]